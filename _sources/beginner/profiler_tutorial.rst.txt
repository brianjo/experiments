.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_profiler_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_profiler_tutorial.py:


PyTorch Profiler
====================================
This recipe explains how to use PyTorch profiler and measure the time and
memory consumption of the model's operators.

Introduction
------------
PyTorch includes a simple profiler API that is useful when user needs
to determine the most expensive operators in the model.

In this recipe, we will use a simple Resnet model to demonstrate how to
use profiler to analyze model performance.

Setup
-----
To install ``torch`` and ``torchvision`` use the following command:

::

   pip install torch torchvision



Steps
-----

1. Import all necessary libraries
2. Instantiate a simple Resnet model
3. Use profiler to analyze execution time
4. Use profiler to analyze memory consumption
5. Using tracing functionality

1. Import all necessary libraries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In this recipe we will use ``torch``, ``torchvision.models``
and ``profiler`` modules:



.. code-block:: default


    import torch
    import torchvision.models as models
    import torch.autograd.profiler as profiler








2. Instantiate a simple Resnet model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Let's create an instance of a Resnet model and prepare an input
for it:



.. code-block:: default


    model = models.resnet18()
    inputs = torch.randn(5, 3, 224, 224)







3. Use profiler to analyze execution time
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

PyTorch profiler is enabled through the context manager and accepts
a number of parameters, some of the most useful are:

- ``record_shapes`` - whether to record shapes of the operator inputs;
- ``profile_memory`` - whether to report amount of memory consumed by
  model's Tensors;
- ``use_cuda`` - whether to measure execution time of CUDA kernels.

Let's see how we can use profiler to analyze the execution time:


.. code-block:: default


    with profiler.profile(record_shapes=True) as prof:
        with profiler.record_function("model_inference"):
            model(inputs)







Note that we can use ``record_function`` context manager to label
arbitrary code ranges with user provided names
(``model_inference`` is used as a label in the example above).
Profiler allows one to check which operators were called during the
execution of a code range wrapped with a profiler context manager.
If multiple profiler ranges are active at the same time (e.g. in
parallel PyTorch threads), each profiling context manager tracks only
the operators of its corresponding range.
Profiler also automatically profiles the async tasks launched
with ``torch.jit._fork`` and (in case of a backward pass)
the backward pass operators launched with ``backward()`` call.

Let's print out the stats for the execution above:


.. code-block:: default


    print(prof.key_averages().table(sort_by="cpu_time_total", row_limit=10))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
                      model_inference         1.60%       4.401ms        99.99%     275.321ms     275.321ms             1  
                         aten::conv2d         0.05%     130.402us        63.95%     176.079ms       8.804ms            20  
                    aten::convolution         0.04%     120.700us        63.90%     175.948ms       8.797ms            20  
                   aten::_convolution         0.07%     201.800us        63.86%     175.828ms       8.791ms            20  
             aten::mkldnn_convolution        63.70%     175.392ms        63.78%     175.626ms       8.781ms            20  
                     aten::batch_norm         0.04%     100.601us        23.73%      65.334ms       3.267ms            20  
         aten::_batch_norm_impl_index         0.06%     169.100us        23.69%      65.233ms       3.262ms            20  
              aten::native_batch_norm        15.81%      43.529ms        23.62%      65.034ms       3.252ms            20  
                     aten::max_pool2d         0.01%      37.200us         8.96%      24.683ms      24.683ms             1  
        aten::max_pool2d_with_indices         8.77%      24.139ms         8.95%      24.646ms      24.646ms             1  
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
    Self CPU time total: 275.347ms


The output will look like (omitting some columns):


.. code-block:: default


    # -------------------------  --------------  ----------  ------------  ---------
    # Name                       Self CPU total   CPU total  CPU time avg  # Calls
    # -------------------------  --------------  ----------  ------------  ---------
    # model_inference            3.541ms         69.571ms    69.571ms      1
    # conv2d                     69.122us        40.556ms    2.028ms       20
    # convolution                79.100us        40.487ms    2.024ms       20
    # _convolution               349.533us       40.408ms    2.020ms       20
    # mkldnn_convolution         39.822ms        39.988ms    1.999ms       20
    # batch_norm                 105.559us       15.523ms    776.134us     20
    # _batch_norm_impl_index     103.697us       15.417ms    770.856us     20
    # native_batch_norm          9.387ms         15.249ms    762.471us     20
    # max_pool2d                 29.400us        7.200ms     7.200ms       1
    # max_pool2d_with_indices    7.154ms         7.170ms     7.170ms       1
    # -------------------------  --------------  ----------  ------------  ---------







Here we see that, as expected, most of the time is spent in convolution (and specifically in ``mkldnn_convolution``
for PyTorch compiled with MKL-DNN support).
Note the difference between self cpu time and cpu time - operators can call other operators, self cpu time exludes time
spent in children operator calls, while total cpu time includes it.

To get a finer granularity of results and include operator input shapes, pass ``group_by_input_shape=True``:


.. code-block:: default


    print(prof.key_averages(group_by_input_shape=True).table(sort_by="cpu_time_total", row_limit=10))

    # (omitting some columns)
    # -------------------------  -----------  --------  -------------------------------------
    # Name                       CPU total    # Calls         Input Shapes
    # -------------------------  -----------  --------  -------------------------------------
    # model_inference            69.571ms     1         []
    # conv2d                     9.019ms      4         [[5, 64, 56, 56], [64, 64, 3, 3], []]
    # convolution                9.006ms      4         [[5, 64, 56, 56], [64, 64, 3, 3], []]
    # _convolution               8.982ms      4         [[5, 64, 56, 56], [64, 64, 3, 3], []]
    # mkldnn_convolution         8.894ms      4         [[5, 64, 56, 56], [64, 64, 3, 3], []]
    # max_pool2d                 7.200ms      1         [[5, 64, 112, 112]]
    # conv2d                     7.189ms      3         [[5, 512, 7, 7], [512, 512, 3, 3], []]
    # convolution                7.180ms      3         [[5, 512, 7, 7], [512, 512, 3, 3], []]
    # _convolution               7.171ms      3         [[5, 512, 7, 7], [512, 512, 3, 3], []]
    # max_pool2d_with_indices    7.170ms      1         [[5, 64, 112, 112]]
    # -------------------------  -----------  --------  --------------------------------------






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------  
                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                   Input Shapes  
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------  
                      model_inference         1.60%       4.401ms        99.99%     275.321ms     275.321ms             1                                             []  
                         aten::conv2d         0.01%      26.900us        16.19%      44.567ms      11.142ms             4  [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [],  
                    aten::convolution         0.01%      32.700us        16.18%      44.540ms      11.135ms             4  [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [],  
                   aten::_convolution         0.02%      49.400us        16.16%      44.508ms      11.127ms             4  [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [],  
             aten::mkldnn_convolution        16.12%      44.397ms        16.15%      44.458ms      11.115ms             4  [[5, 64, 56, 56], [64, 64, 3, 3], [], [], [],  
                         aten::conv2d         0.01%      16.001us        12.66%      34.868ms      11.623ms             3  [[5, 512, 7, 7], [512, 512, 3, 3], [], [], []  
                    aten::convolution         0.01%      15.100us        12.66%      34.852ms      11.617ms             3  [[5, 512, 7, 7], [512, 512, 3, 3], [], [], []  
                   aten::_convolution         0.01%      24.700us        12.65%      34.837ms      11.612ms             3  [[5, 512, 7, 7], [512, 512, 3, 3], [], [], []  
             aten::mkldnn_convolution        12.63%      34.781ms        12.64%      34.812ms      11.604ms             3  [[5, 512, 7, 7], [512, 512, 3, 3], [], [], []  
                         aten::conv2d         0.01%      15.700us        10.18%      28.029ms       9.343ms             3  [[5, 128, 28, 28], [128, 128, 3, 3], [], [],   
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------  
    Self CPU time total: 275.347ms


4. Use profiler to analyze memory consumption
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

PyTorch profiler can also show the amount of memory (used by the model's tensors)
that was allocated (or released) during the execution of the model's operators.
In the output below, 'self' memory corresponds to the memory allocated (released)
by the operator, excluding the children calls to the other operators.
To enable memory profiling functionality pass ``profile_memory=True``.


.. code-block:: default


    with profiler.profile(profile_memory=True, record_shapes=True) as prof:
        model(inputs)

    print(prof.key_averages().table(sort_by="self_cpu_memory_usage", row_limit=10))

    # (omitting some columns)
    # ---------------------------  ---------------  ---------------  ---------------
    # Name                         CPU Mem          Self CPU Mem     Number of Calls
    # ---------------------------  ---------------  ---------------  ---------------
    # empty                        94.79 Mb         94.79 Mb         123
    # resize_                      11.48 Mb         11.48 Mb         2
    # addmm                        19.53 Kb         19.53 Kb         1
    # empty_strided                4 b              4 b              1
    # conv2d                       47.37 Mb         0 b              20
    # ---------------------------  ---------------  ---------------  ---------------

    print(prof.key_averages().table(sort_by="cpu_memory_usage", row_limit=10))

    # (omitting some columns)
    # ---------------------------  ---------------  ---------------  ---------------
    # Name                         CPU Mem          Self CPU Mem     Number of Calls
    # ---------------------------  ---------------  ---------------  ---------------
    # empty                        94.79 Mb         94.79 Mb         123
    # batch_norm                   47.41 Mb         0 b              20
    # _batch_norm_impl_index       47.41 Mb         0 b              20
    # native_batch_norm            47.41 Mb         0 b              20
    # conv2d                       47.37 Mb         0 b              20
    # convolution                  47.37 Mb         0 b              20
    # _convolution                 47.37 Mb         0 b              20
    # mkldnn_convolution           47.37 Mb         0 b              20
    # empty_like                   47.37 Mb         0 b              20
    # max_pool2d                   11.48 Mb         0 b              1
    # max_pool2d_with_indices      11.48 Mb         0 b              1
    # resize_                      11.48 Mb         11.48 Mb         2
    # addmm                        19.53 Kb         19.53 Kb         1
    # adaptive_avg_pool2d          10.00 Kb         0 b              1
    # mean                         10.00 Kb         0 b              1
    # ---------------------------  ---------------  ---------------  ---------------





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                          aten::empty         0.18%     430.604us         0.18%     430.604us       4.140us      94.79 Mb      94.79 Mb           104  
                        aten::resize_         0.01%      16.300us         0.01%      16.300us       8.150us      11.48 Mb      11.48 Mb             2  
                          aten::addmm         1.32%       3.197ms         1.33%       3.212ms       3.212ms      19.53 Kb      19.53 Kb             1  
                            aten::add         0.11%     256.401us         0.11%     256.401us      12.820us         160 b         160 b            20  
                  aten::empty_strided         0.00%       3.400us         0.00%       3.400us       3.400us           4 b           4 b             1  
                         aten::conv2d         0.05%     109.200us        63.24%     153.213ms       7.661ms      47.37 Mb           0 b            20  
                    aten::convolution         0.05%     111.400us        63.20%     153.104ms       7.655ms      47.37 Mb           0 b            20  
                   aten::_convolution         0.08%     188.000us        63.15%     152.992ms       7.650ms      47.37 Mb           0 b            20  
             aten::mkldnn_convolution        63.00%     152.621ms        63.07%     152.804ms       7.640ms      47.37 Mb           0 b            20  
                    aten::as_strided_         0.02%      46.500us         0.02%      46.500us       2.325us           0 b           0 b            20  
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
    Self CPU time total: 242.266ms

    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                          aten::empty         0.18%     430.604us         0.18%     430.604us       4.140us      94.79 Mb      94.79 Mb           104  
                     aten::batch_norm         0.04%     108.201us        24.94%      60.421ms       3.021ms      47.41 Mb           0 b            20  
         aten::_batch_norm_impl_index         0.07%     160.101us        24.90%      60.313ms       3.016ms      47.41 Mb           0 b            20  
              aten::native_batch_norm        16.48%      39.934ms        24.81%      60.106ms       3.005ms      47.41 Mb           0 b            20  
                         aten::conv2d         0.05%     109.200us        63.24%     153.213ms       7.661ms      47.37 Mb           0 b            20  
                    aten::convolution         0.05%     111.400us        63.20%     153.104ms       7.655ms      47.37 Mb           0 b            20  
                   aten::_convolution         0.08%     188.000us        63.15%     152.992ms       7.650ms      47.37 Mb           0 b            20  
             aten::mkldnn_convolution        63.00%     152.621ms        63.07%     152.804ms       7.640ms      47.37 Mb           0 b            20  
                     aten::empty_like         0.05%     119.801us         0.10%     241.703us      12.085us      47.37 Mb           0 b            20  
                     aten::max_pool2d         0.00%       8.300us         9.08%      22.002ms      22.002ms      11.48 Mb           0 b             1  
    ---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
    Self CPU time total: 242.266ms


5. Using tracing functionality
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Profiling results can be outputted as a .json trace file:


.. code-block:: default


    with profiler.profile() as prof:
        with profiler.record_function("model_inference"):
            model(inputs)

    prof.export_chrome_trace("trace.json")







User can examine the sequence of profiled operators after loading the trace file
in Chrome (``chrome://tracing``):

.. image:: https://pytorch.org/tutorials/_images/trace_img.png
   :scale: 25 %

Learn More
----------

Take a look at the following recipes/tutorials to continue your learning:

-  `PyTorch Benchmark <https://pytorch.org/tutorials/recipes/recipes/benchmark.html>`_
-  `Visualizing models, data, and training with TensorBoard <https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html>`_ tutorial



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  4.247 seconds)


.. _sphx_glr_download_beginner_profiler_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: profiler_tutorial.py <profiler_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: profiler_tutorial.ipynb <profiler_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
